{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3dc9fd",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f45cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import getpass\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import util\n",
    "from siren import Siren\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "from util import get_clamped_psnr\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from training import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123edca2",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4b4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "logdir = f\"/tmp/{getpass.getuser()}\"\n",
    "num_iters = 50000\n",
    "learning_rate = 2e-4\n",
    "seed = random.randint(1, int(1e6))\n",
    "full_dataset = False\n",
    "image_id = 15\n",
    "layer_size = 28\n",
    "num_layers = 10\n",
    "w0 = 30.0\n",
    "w0_initial = 30.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddbd1d",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc995f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrigTrainer(Trainer):\n",
    "    def __init__(self, representation, lr=1e-3, print_freq=1):\n",
    "        \"\"\"Model to learn a representation of a single datapoint.\n",
    "\n",
    "        Args:\n",
    "            representation (siren.Siren): Neural net representation of image to\n",
    "                be trained.\n",
    "            lr (float): Learning rate to be used in Adam optimizer.\n",
    "            print_freq (int): Frequency with which to print losses.\n",
    "        \"\"\"\n",
    "        super().__init__(representation, lr, print_freq)\n",
    "\n",
    "    def train(self, coordinates, features, num_iters):\n",
    "        \"\"\"Fit neural net to image.\n",
    "\n",
    "        Args:\n",
    "            coordinates (torch.Tensor): Tensor of coordinates.\n",
    "                Shape (num_points, coordinate_dim).\n",
    "            features (torch.Tensor): Tensor of features. Shape (num_points, feature_dim).\n",
    "            num_iters (int): Number of iterations to train for.\n",
    "        \"\"\"\n",
    "        with tqdm.trange(num_iters, ncols=100) as t:\n",
    "            for i in t:\n",
    "                # Update model\n",
    "                self.optimizer.zero_grad()\n",
    "                predicted = self.representation(coordinates)\n",
    "                loss = self.loss_func(predicted, features)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Calculate psnr\n",
    "                psnr = get_clamped_psnr(predicted, features)\n",
    "\n",
    "                # Print results and update logs\n",
    "                log_dict = {'loss': loss.item(),\n",
    "                            'psnr': psnr,\n",
    "                            'best_psnr': self.best_vals['psnr']}\n",
    "                t.set_postfix(**log_dict)\n",
    "                for key in ['loss', 'psnr']:\n",
    "                    self.logs[key].append(log_dict[key])\n",
    "\n",
    "                # Update best values\n",
    "                if loss.item() < self.best_vals['loss']:\n",
    "                    self.best_vals['loss'] = loss.item()\n",
    "                if psnr > self.best_vals['psnr']:\n",
    "                    self.best_vals['psnr'] = psnr\n",
    "                    # If model achieves best PSNR seen during training, update\n",
    "                    # model\n",
    "                    if i > int(num_iters / 2.):\n",
    "                        for k, v in self.representation.state_dict().items():\n",
    "                            self.best_model[k].copy_(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5070b",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d735de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaynieles/dev/aec/venv/lib/python3.8/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "# Set up torch and cuda\n",
    "dtype = torch.float32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor' if torch.cuda.is_available() else 'torch.FloatTensor')\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "if full_dataset:\n",
    "    min_id, max_id = 1, 24  # Kodak dataset runs from kodim01.png to kodim24.png\n",
    "else:\n",
    "    min_id, max_id = image_id, image_id\n",
    "    \n",
    "# Dictionary to register mean values (both full precision and half precision)\n",
    "results = {'fp_bpp': [], 'hp_bpp': [], 'fp_psnr': [], 'hp_psnr': []}\n",
    "\n",
    "# Create directory to store experiments\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe25c01",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cbd5a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47050/9764974.py:6: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imageio.imread(f\"kodak-dataset/kodim{str(i).zfill(2)}.png\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 29.9kB\n",
      "Full precision bpp: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 50000/50000 [08:36<00:00, 96.74it/s, best_psnr=29.3, loss=0.00123, psnr=29.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training psnr: 29.32\n",
      "Half precision bpp: 0.30\n",
      "Half precision psnr: 29.20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit images\n",
    "for i in range(min_id, max_id + 1):\n",
    "    print(f'Image {i}')\n",
    "\n",
    "    # Load image\n",
    "    img = imageio.imread(f\"kodak-dataset/kodim{str(i).zfill(2)}.png\")\n",
    "    img = transforms.ToTensor()(img).float().to(device, dtype)\n",
    "\n",
    "    # Setup model\n",
    "    func_rep = Siren(\n",
    "        dim_in=2,\n",
    "        dim_hidden=layer_size,\n",
    "        dim_out=3,\n",
    "        num_layers=num_layers,\n",
    "        final_activation=torch.nn.Identity(),\n",
    "        w0_initial=w0_initial,\n",
    "        w0=w0\n",
    "    ).to(device)\n",
    "\n",
    "    # Set up training\n",
    "    trainer = OrigTrainer(func_rep, lr=learning_rate)\n",
    "    coordinates, features = util.to_coordinates_and_features(img)\n",
    "    coordinates, features = coordinates.to(device, dtype), features.to(device, dtype)\n",
    "\n",
    "    # Calculate model size. Divide by 8000 to go from bits to kB\n",
    "    model_size = util.model_size_in_bits(func_rep) / 8000.\n",
    "    print(f'Model size: {model_size:.1f}kB')\n",
    "    fp_bpp = util.bpp(model=func_rep, image=img)\n",
    "    print(f'Full precision bpp: {fp_bpp:.2f}')\n",
    "\n",
    "    # Train model in full precision\n",
    "    trainer.train(coordinates, features, num_iters=num_iters)\n",
    "    print(f'Best training psnr: {trainer.best_vals[\"psnr\"]:.2f}')\n",
    "\n",
    "    # Log full precision results\n",
    "    results['fp_bpp'].append(fp_bpp)\n",
    "    results['fp_psnr'].append(trainer.best_vals['psnr'])\n",
    "\n",
    "    # Save best model\n",
    "    torch.save(trainer.best_model, logdir + f'/best_model_{i}.pt')\n",
    "\n",
    "    # Update current model to be best model\n",
    "    func_rep.load_state_dict(trainer.best_model)\n",
    "\n",
    "    # Save full precision image reconstruction\n",
    "    with torch.no_grad():\n",
    "        img_recon = func_rep(coordinates).reshape(img.shape[1], img.shape[2], 3).permute(2, 0, 1)\n",
    "        save_image(torch.clamp(img_recon, 0, 1).to('cpu'), logdir + f'/fp_reconstruction_{i}.png')\n",
    "\n",
    "    # Convert model and coordinates to half precision. Note that half precision\n",
    "    # torch.sin is only implemented on GPU, so must use cuda\n",
    "    if torch.cuda.is_available():\n",
    "        func_rep = func_rep.half().to('cuda')\n",
    "        coordinates = coordinates.half().to('cuda')\n",
    "\n",
    "        # Calculate model size in half precision\n",
    "        hp_bpp = util.bpp(model=func_rep, image=img)\n",
    "        results['hp_bpp'].append(hp_bpp)\n",
    "        print(f'Half precision bpp: {hp_bpp:.2f}')\n",
    "\n",
    "        # Compute image reconstruction and PSNR\n",
    "        with torch.no_grad():\n",
    "            img_recon = func_rep(coordinates).reshape(img.shape[1], img.shape[2], 3).permute(2, 0, 1).float()\n",
    "            hp_psnr = util.get_clamped_psnr(img_recon, img)\n",
    "            save_image(torch.clamp(img_recon, 0, 1).to('cpu'), logdir + f'/hp_reconstruction_{i}.png')\n",
    "            print(f'Half precision psnr: {hp_psnr:.2f}')\n",
    "            results['hp_psnr'].append(hp_psnr)\n",
    "    else:\n",
    "        results['hp_bpp'].append(fp_bpp)\n",
    "        results['hp_psnr'].append(0.0)\n",
    "\n",
    "    # Save logs for individual image\n",
    "    with open(logdir + f'/logs{i}.json', 'w') as f:\n",
    "        json.dump(trainer.logs, f)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c38fab9",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5870357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Full results:')\n",
    "print(results)\n",
    "with open(logdir + f'/results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "    \n",
    "# Compute and save aggregated results\n",
    "results_mean = {key: util.mean(results[key]) for key in results}\n",
    "with open(logdir + f'/results_mean.json', 'w') as f:\n",
    "    json.dump(results_mean, f)\n",
    "\n",
    "print('Aggregate results:')\n",
    "print(f'Full precision, bpp: {results_mean[\"fp_bpp\"]:.2f}, psnr: {results_mean[\"fp_psnr\"]:.2f}')\n",
    "print(f'Half precision, bpp: {results_mean[\"hp_bpp\"]:.2f}, psnr: {results_mean[\"hp_psnr\"]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3901078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
